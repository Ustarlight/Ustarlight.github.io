---
layout: post
title:  "2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet"
date:   2023-11-08 16:10:45 +0800
categories: share
---

多阶段法和单阶段法在性能上的主要区别如下：

- 多阶段法具有较高的精度，但速度较慢；
- 单阶段法具有较快的速度，但准确率不如前者。

造成单阶段法精度差的一个主要原因是：正负样本数量的极度失衡，导致网络较难训练。在双阶段目标检测方法中，第一个RPN阶段得到的候选区域数量要远远小于单阶段法产生的候选区域，因此不会产生严重的正负样本数量失衡问题。

RetinaNet的提出就是为了解决这一问题，RetinaNet于Kaming大神在2017年提出，其中使用了FPN、ResNet，并提出了大名鼎鼎的Focal Loss，以及一种参数初始化的方法。RetinaNet是目前使用最广泛的单阶段目标检测模型之一。

SSD使用**难负样本挖掘**来解决正负样本比例极度不平衡的问题，而难负样本挖掘有两个问题：

1. 样本利用不充分：只使用了一小部分较难的负样本，大部分负样本都没有使用，利用率低；
2. 挖掘难以控制：利用正样本数量的3倍来挖负样本，有时挖太多，有时挖太少，使用负样本的数量难以确定。

RetinaNet通过修改标准交叉熵损失函数，提出了**focal loss损失函数**：通过减少易分类样本的权重，使得模型在训练时更专注于难分类的样本，从而充分地利用所有样本。Focal loss使得单阶段法目标检测网络可以达到多阶段法的准确率，同时保持原有的速度。

**整体框架**

RetinaNet的整体框架如下图所示，RetinaNet的架构比较简洁，采用ResNet+FPN作为Backbone，在不同尺度的多个检测层上都关联了锚框，随后送入分类与回归子网络得到精细的检测框，下面会对每一部分进行详细的介绍。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.18.11.png)

**数据增广**

RetinaNet对输入图像只进行了如下步骤的数据增广操作，需要注意的是RetinaNet提供了两种不同的单尺度/多尺度训练策略：

- 随机水平翻转；
- 单尺度训练：图像短边等比例缩放至800，且长边不超过1333
- 多尺度训练：图像短边等比例缩放至{640, 672, 704, 736, 768, 800}中的任意一个，且长边不超过1333

**基础网络**

**Backbone**

采用ResNet50或ResNet101作为基础网络，所有的ResNet网络都由{Res1, Res2, Res3, Res4, Res5}5个模块组成，不管是ResNet50/101/152，这5个模块的下采样倍率都分别是2、4、8、16、32，RetinaNet选取下采样倍率为8、16、32的Res3,、Res4、Res5这3个模块作为初始的检测层。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.21.13.png)

### neck

采用FPN对初始检测层上的特征进行强化（此处涉及到的所有卷积层后都没有BN和ReLU）：

1. 低层特征L经过1x1卷积，得到L'；
2. 高层特征H经过上采样，得到H'；
3. 将L'和H'进行特征融合得到C=L'+H'；
4. 将融合后的特征经过3x3卷积，得到最终强化后的特征P；
5. 将融合后的特征C作为后续特征融合操作的高层特征（相当于本次操作中的高层特征H）。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.22.18.png)

采用FPN对初始的检测层进行强化得到P3、P4、P5，随后在P5后面连续使用下采样倍率为2的卷积层生成P6、P7。因此RetinaNet共有P3（下采样倍数为8）、P4（下采样倍数为16）、P5（下采样倍数为32）、P6（下采样倍数为64）、P7（下采样倍数为128）共5个检测层。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.24.04.png)

### head

在RetinaNet中，分类分支和回归分支都分别额外增加了4个卷积层，导致检测子网络的深度变深。此外，RetinaNet的所有检测层都共用一个检测子网络。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.25.18.png)

**Focal Loss**

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.27.45.png)

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.32.03.png)

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.32.48.png)

我们再总结一下Focal Loss与SSD中难负样本挖掘的关系：

| 难负样本挖掘                           | Focal Loss                       |
| -------------------------------------- | -------------------------------- |
| Hard Weight（硬加权）                  | Soft Weight（软加权）            |
| 选中的负样本，权重为1                  | 分类越正确（易分样本），权重越低 |
| 滤掉的负样本，权重为0                  | 分类越错误（难分样本），权重越高 |
| 选取所有正样本及固定比例或数量的负样本 | 所有样本参与训练                 |
| 不能充分利用所有样本                   | 能够充分利用所有的样本           |

难负样本挖掘相当于采用一刀切的方式，将分类最不准确的那些难负样本在损失函数上的权重设置为1，其余负样本的权重设置为0，相比之下Focal Loss的权重比较柔和。虽然难负样本挖掘在缓解正负样本比例失衡的问题上会起到一定作用，但是无法像Focal Loss一样充分利用所有样本，因此Focal Loss是处理正负样本比例失衡问题时的首要考虑方案。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.34.23.png)

**模型初始化**

模型初始化是RetinaNet中一个非常重要的细节。

基础网络ResNet部分是用ImageNet预训练的模型进行初始化，其次所有新添加的卷积层都是用σ = 0.01的高斯函数来随机初始化权重w。

除了分类子网络中的最后一个卷积层的偏置b，其他卷积层的偏置都初始化为0。分类子网络中的最后一个卷积层的偏置b用下面这个公式进行初始化：
$$
b = -log(\frac{1-\pi}{\pi})
$$
其中π = 0.01，这意味着在训练开始时，每个锚框的前景得分大约是0.01，代表着几乎99%的锚框都预测为背景，这样做的目的是为了大大降低损失函数的初始值。 接下来详细讲一下如何得到这一结论的。

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.40.57.png)

通过改变最后一个卷积层初始化时的偏置值，将锚框的初始预测概率从0.5降低至0.01，相当于本来不确定锚框属于前景还是属于背景，现在直接认为99%的锚框都是背景，锚框属于前景的概率只有1%。

从降低损失函数的角度来分析一下，当预测值p=0.5时，对于正、负样本（真值为1、0）来说，交叉熵损失函数如下：

![](./2023-11-08-some-review-about-vision--2D-Object-Detection-Anchor-based-One-Stage-RetinaNet/截屏2023-11-08 16.42.26.png)

在正负样本比例失衡的情况下，采用这种初始化方式可以显著降低损失函数的初始值：

- 当正负样本为1:10时，Loss从0.693+0.693×10=**7.623**变为4.605+0.01×10=**4.705**，**减小1.62倍**
- 当正负样本为1:100时，Loss从0.693+0.693×100=**69.993**变为4.605+0.01×100=**5.605**，**减小12.49倍**
- 当正负样本为1:1000时，Loss从0.693+0.693×1000=**693.693**变为4.605+0.01×1000=**14.605**，**减小47.5倍**
- 当正负样本为1:10000时，Loss从0.693+0.693×10000=**6930.693**变为4.605+0.01×10000=**104.605**，**减小66.26倍**

当损失函数的初始值大幅降低时，网络会更加容易训练。在实际调试过程中，RetinaNet的初始Loss只有个位数，若将模型初始化的方式回调到正常初始化方式，RetinaNet的初始Loss会暴涨到几十，导致模型难以训练。

**总结**

RetinaNet深入分析了极度失衡的正（前景）、负（背景）样本比例是单阶段检测方法的精度低于双阶段检测方法的原因之一，提出了一种简洁且实用的 Focal Loss，使得网络更加关注那些难分样本（错误分类的样本），提升了网络的预测能力；同时针对目标检测任务，设计了 RetinaNet 网络，结合 Focal Loss 使得单阶段检测方法在精度上能够达到乃至超过双阶段检测方法；另外设计了一种模型初始化方法，大幅减少了网络的初始化Loss，使得网络的训练变得更加容易。
